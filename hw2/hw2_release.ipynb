{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPUiK8-evUQt"
   },
   "source": [
    "# **CS 1810 Homework 2**\n",
    "---\n",
    "To account for potential version issues, try the following in your terminal:\n",
    "\n",
    "1. Create a new environment with `python3 -m venv venv`\n",
    "2. Activate that environment with `source venv/bin/activate`\n",
    "3. Make sure the interpreter in the top right corner of your VSCode (or whatever you use to run your code is venv).\n",
    "4. If you get a \"install kernel\" message, press it.\n",
    "5. Run `pip install -r requirements.txt`\n",
    "6. Run the remainder of this notebook.\n",
    "\n",
    "Note that this is not necessary but can help prevent any issues due to package versions.\n",
    "\n",
    "**The following notebook is meant to help you work through Problems 1 and 3 on Homework 2. You are by no means required to use it, nor are you required to fill out/use any of the boilerplate code/functions. You are welcome to implement the functions however you wish.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1178,
     "status": "ok",
     "timestamp": 1739570682438,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "8vi6ULCLvUQw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as c\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import softmax\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from T2_P3_TestCases import test_p3_softmax, test_p3_knn\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Tuple\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data for Problem 1\n",
    "t_obs, y_obs = np.genfromtxt(\"data/planet-obs.csv\", delimiter = ',').T\n",
    "\"\"\"\n",
    "Load and randomly partition the dataset into 10 folds for cross validation.\n",
    "\n",
    ":param planet-obs.csv: CSV file with two columns (t, y)\n",
    ":return:\n",
    "    t_obs: list of length 10, each element is a numpy array of input values for one fold\n",
    "    y_obs: list of length 10, each element is a numpy array of labels for one fold, shape (n_i, 1)\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "pass\n",
    "\n",
    "### Data for Problem 3\n",
    "data = pd.read_csv(\"data/hr.csv\")\n",
    "mapper = {\n",
    "    \"Automatically Rejected\": 0,\n",
    "    \"Require Guarantor\": 1,\n",
    "    \"Automatically Accepted\": 2\n",
    "}\n",
    "data['Type'] = data['Type'].map(mapper)\n",
    "X_applicants = data[['Debt to Income Ratio', 'Credit Score']].values\n",
    "\n",
    "# transformation as described in problem statement\n",
    "def transform(X):\n",
    "  X = np.stack((X[:,0]*20/0.7-7.5, X[:,1]/140 - (500/140+0.5)), axis=1)\n",
    "  return X\n",
    "# Transformation\n",
    "X_applicants = transform(X_applicants)\n",
    "y_applicants = data['Type'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDmd0_vZvUQy"
   },
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ce56ZRllvUQy"
   },
   "source": [
    "## Problem 1 Subpart 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1739570686940,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "2NCwCEFGvUQy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def basis1(t):\n",
    "    return np.stack([np.ones(len(t)), t], axis=1)\n",
    "\n",
    "def basis2(t):\n",
    "    \"\"\"\n",
    "    Transform t into your chosen basis \n",
    "\n",
    "    :param t: a numpy array of values to transform. Shape is (n,)\n",
    "    :return: a 2D array in which each row corresponds to a basis transformation of\n",
    "             an input value. Shape should be (n x d)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def basis3(t):\n",
    "    \"\"\"\n",
    "    Transform t into another one of your chosen basis\n",
    "\n",
    "    :param t: a numpy array of values to transform. Shape is (n,)\n",
    "    :return: a 2D array in which each row corresponds to a basis transformation of\n",
    "             an input value. Shape should be (n x d)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1739570687414,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "6FfLrzZdvUQz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogisticRegressor:\n",
    "    def __init__(self, eta, runs):\n",
    "        self.eta = eta\n",
    "        self.runs = runs\n",
    "        self.W = None\n",
    "\n",
    "    def fit(self, x, y, w_init):\n",
    "        \"\"\"\n",
    "        Optimize the weights W to minimize the negative log-likelihood by using gradient descent\n",
    "\n",
    "        :param x: a 2D numpy array of transformed feature values. Shape is (n x d), where d depends on your basis functions\n",
    "        :param y: a 2D numpy array of output values. Shape is (n x 1)\n",
    "        :param w_init: a 2D numpy array that initializes the weights. Shape is (d x 1)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # Keep this for the autograder\n",
    "        self.W = w_init\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict classification probability of transformed input x\n",
    "\n",
    "        :param x: a 2D numpy array of transformed feature values. Shape is (n x d), where d depends on your basis functions\n",
    "        :return: a 2D numpy array of predicted probabilities given current weights. Shape should be (n x 1)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Part 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have written function signatures and descriptions that you may consider following to implement cross-validation. Of course, feel free to implement things as you please, as long as you implement what is requested by the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def stack_folds(folds):\n",
    "    \"\"\"\n",
    "    Concatenate a list of fold arrays along the first axis.\n",
    "\n",
    "    :param folds: list of numpy arrays, each with shape (n_i, d)\n",
    "    :return: numpy array with shape (sum_i n_i, d)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def probs_to_labels(p, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Convert predicted probabilities into {0,1} labels using a threshold.\n",
    "\n",
    "    :param p: numpy array of probabilities, shape (n,1) or (n,)\n",
    "    :param threshold: float in [0,1], decision threshold\n",
    "    :return: numpy array of integer labels in {0,1}, shape (n,1)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def compute_basis_folds(t_obs, basis_fn):\n",
    "    \"\"\"\n",
    "    Apply a basis function to each fold once.\n",
    "\n",
    "    :param t_obs: list of numpy arrays, each fold input, shape (n_i, 1) or (n_i,)\n",
    "    :param basis_fn: function mapping t -> X (transformed features)\n",
    "    :return: list of numpy arrays X_obs, where X_obs[i] = basis_fn(t_obs[i])\n",
    "             each X_obs[i] has shape (n_i, d)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def classification_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute average 0/1 classification error.\n",
    "\n",
    "    :param y_true: numpy array of true labels, shape (n,1) or (n,)\n",
    "    :param y_pred: numpy array of predicted labels, shape (n,1) or (n,)\n",
    "    :return: float, fraction misclassified\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def cross_validate_single_basis(t_obs, y_obs, basis_fn, k=10, eta=0.001, runs=1000, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross validation for ONE basis representation, using the provided fold split.\n",
    "\n",
    "    Procedure:\n",
    "      1) Transform each fold once using basis_fn\n",
    "      2) For fold i:\n",
    "           - train on all folds except i\n",
    "           - validate on fold i\n",
    "      3) Return the per-fold classification errors\n",
    "\n",
    "    :param t_obs: list of length k, each entry is a numpy array of t values for fold i\n",
    "    :param y_obs: list of length k, each entry is a numpy array of labels for fold i, shape (n_i,1)\n",
    "    :param basis_fn: basis function used to transform t -> X\n",
    "    :param k: int, number of folds (should match len(t_obs))\n",
    "    :param eta: float, learning rate passed to LogisticRegressor\n",
    "    :param runs: int, number of gradient steps/iterations passed to LogisticRegressor\n",
    "    :param threshold: float, probability threshold for turning probs into labels\n",
    "    :return: numpy array of fold errors, shape (k,)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "\n",
    "def run_cv_all_bases(t_obs, y_obs, bases, k=10, eta=0.001, runs=1000, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Convenience wrapper to run CV for multiple basis functions.\n",
    "\n",
    "    :param t_obs: list of folds for t\n",
    "    :param y_obs: list of folds for y\n",
    "    :param bases: list of tuples (name, basis_fn)\n",
    "    :param k: int, number of folds\n",
    "    :param eta: float, learning rate\n",
    "    :param runs: int, iterations\n",
    "    :param threshold: float, probability threshold\n",
    "    :return: dict mapping basis name -> numpy array of fold errors, shape (k,)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Run the Cross Validation for the 3 Basis Functions \n",
    "bases = [(\"basis1\", basis1), (\"basis2\", basis2), (\"basis3\", basis3)]\n",
    "cv_results = run_cv_all_bases(t_obs, y_obs, bases, k=10, eta=0.001, runs=1000, threshold=0.5)\n",
    "\n",
    "for name in cv_results:\n",
    "    errs = cv_results[name]\n",
    "    print(f\"{name} fold errors:\")\n",
    "    print(errs)\n",
    "    print(f\"{name} average error (10-fold): {errs.mean():.6f}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2nQwbk7vUQz"
   },
   "source": [
    "## Plotting Functions for Problem 1, Subpart 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1739570690424,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "VklRnTZyvUQz"
   },
   "outputs": [],
   "source": [
    "# Function to visualize prediction lines\n",
    "# Takes as input last_x, last_y, [list of models], basis function, title\n",
    "# last_x and last_y should specifically be the dataset that the last model\n",
    "# in [list of models] was trained on\n",
    "def visualize_prediction_lines(last_x, last_y, models, basis, title):\n",
    "    # Plot setup\n",
    "    green = mpatches.Patch(color='green', label='Ground truth model')\n",
    "    black = mpatches.Patch(color='black', label='Mean of learned models')\n",
    "    purple = mpatches.Patch(color='purple', label='Model learned from displayed dataset')\n",
    "    plt.legend(handles=[green, black, purple], loc='lower right')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Observed')\n",
    "    plt.axis([0, 6, -.1, 1.1]) # Plot ranges\n",
    "\n",
    "    # Plot dataset that last model in models (models[-1]) was trained on\n",
    "    cmap = c.ListedColormap(['r', 'b'])\n",
    "    plt.scatter(last_x, last_y, c=last_y, cmap=cmap, linewidths=1, edgecolors='black')\n",
    "\n",
    "    # Plot models\n",
    "    X_pred = np.linspace(0, 6, 1000)\n",
    "    X_pred_transformed = basis(X_pred)\n",
    "\n",
    "    ## Ground truth model\n",
    "    plt.plot(X_pred, np.cos(1.1*X_pred + 1) * 0.4 + 0.5, 'g', linewidth=5)\n",
    "\n",
    "    ## Individual learned logistic regressor models\n",
    "    Y_hats = []\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        Y_hat = model.predict(X_pred_transformed)\n",
    "        Y_hats.append(Y_hat)\n",
    "        if i < len(models) - 1:\n",
    "            plt.plot(X_pred, Y_hat, linewidth=.3)\n",
    "        else:\n",
    "            plt.plot(X_pred, Y_hat, 'purple', linewidth=3)\n",
    "\n",
    "    # Mean / expectation of learned models over all datasets\n",
    "    plt.plot(X_pred, np.mean(Y_hats, axis=0), 'k', linewidth=5)\n",
    "\n",
    "    plt.savefig('img_output/' + title + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1628,
     "status": "ok",
     "timestamp": 1739570692049,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "87KdYWwEvUQ0",
    "outputId": "21136e40-abb7-4319-83f8-a2fd79569d00"
   },
   "outputs": [],
   "source": [
    "def plot_results(basis, title):\n",
    "    eta = 0.001\n",
    "    runs = 1000\n",
    "\n",
    "    # For Problem 1.4\n",
    "    test_points_1 = []\n",
    "    test_points_2 = []\n",
    "    t1 = basis(np.array([0.1]))\n",
    "    t2 = basis(np.array([3.2]))\n",
    "\n",
    "    all_models = []\n",
    "    for i in range(10):\n",
    "        x, y = t_obs[i], y_obs[i]\n",
    "        x_transformed = basis(x)\n",
    "        model = LogisticRegressor(eta=eta, runs=runs)\n",
    "        model.fit(x_transformed, y, np.zeros((x_transformed.shape[1], 1)))\n",
    "        all_models.append(model)\n",
    "\n",
    "        if basis == basis3:\n",
    "            # extract values from (1 x 1) array\n",
    "            pred_1 = model.predict(t1)[0, 0]\n",
    "            pred_2 = model.predict(t2)[0, 0]\n",
    "            if i == 0:\n",
    "                print(f\"Classification probabilities for t = 0.1: {pred_1}, t = 3.2: {pred_2}\")\n",
    "            test_points_1.append(pred_1)\n",
    "            test_points_2.append(pred_2)\n",
    "\n",
    "    if basis == basis3:\n",
    "        print(f\"Model variances for t = 0.1: {np.var(test_points_1)}, t = 3.2: {np.var(test_points_2)}\")\n",
    "    visualize_prediction_lines(x, y, all_models, basis, title)\n",
    "\n",
    "plot_results(basis1, 'basis1')\n",
    "plot_results(basis2, 'basis2')\n",
    "plot_results(basis3, 'basis3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfI-rZv0vUQ0"
   },
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739570692049,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "vplfRxTjvUQ0"
   },
   "outputs": [],
   "source": [
    "class GaussianGenerativeModel:\n",
    "    def __init__(self, is_shared_covariance=False):\n",
    "        self.is_shared_covariance = is_shared_covariance\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute the means and (shared) covariance matrix of the data. Compute the prior over y.\n",
    "\n",
    "        :param X: a 2D numpy array of (transformed) feature values. Shape is (n x 2)\n",
    "        :param y: a 1D numpy array of target values (Automatically Rejected=0, Require Guarantor=1, Automatically Accepted=2).\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_pred):\n",
    "        \"\"\"\n",
    "        Predict classes of points given feature values in X_pred\n",
    "\n",
    "        :param X_pred: a 2D numpy array of (transformed) feature values. Shape is (n x 2)\n",
    "        :return: a 1D numpy array of predicted classes (Automatically Rejected=0, Require Guarantor=1, Automatically Accepted=2).\n",
    "                 Shape should be (n,)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, X_pred):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def negative_log_likelihood(self, X, y):\n",
    "        \"\"\"\n",
    "        Given the data X, use previously calculated class means and covariance matrix to\n",
    "        calculate the negative log likelihood of the data\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739570692049,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "9IUkBIQKvUQ0"
   },
   "outputs": [],
   "source": [
    "class SoftmaxRegression:\n",
    "    def __init__(self, eta, lam, verbose=True):\n",
    "        self.eta = eta\n",
    "        self.lam = lam\n",
    "        self.W = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # Some helper functions may go here:\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the weights W of softmax regression using gradient descent with L2 regularization\n",
    "        Use the results from Problem 2 to find an expression for the gradient\n",
    "        \n",
    "        :param X: a 2D numpy array of (transformed) feature values. Shape is (n x 2)\n",
    "        :param y: a 1D numpy array of target values (Automatically Rejected=0, Require Guarantor=1, Automatically Accepted=2).\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    # Input is (n x 2) array\n",
    "    def predict(self, X_pred):\n",
    "        \"\"\"\n",
    "        Predict classes of points given feature values in X_pred\n",
    "        \n",
    "        :param X_pred: a 2D numpy array of (transformed) feature values. Shape is (n x 2)\n",
    "        :return: a 1D numpy array of predicted classes (Automatically Rejected=0, Require Guarantor=1, Automatically Accepted=2).\n",
    "                 Shape should be (n,)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    # Input is (n x 2) array\n",
    "    def predict_proba(self, X_pred):\n",
    "        \"\"\"    \n",
    "        Predict classification probabilities of points given feature values in X_pred\n",
    "        \n",
    "        :param X_pred: a 2D numpy array of (transformed) feature values. Shape is (n x 2)\n",
    "        :return: a 2D numpy array of predicted class probabilities (Automatically Rejected=index 0, Require Guarantor=index 1, Automatically Accepted=index 2).\n",
    "                 Shape should be (n x 3)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739570692050,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "JKx0A4lsvUQ0"
   },
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.K = k\n",
    "\n",
    "    # Helper functions go here: \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        In KNN, \"fitting\" can be as simple as storing the data, so this has been written for you.\n",
    "        If you'd like to add some preprocessing here without changing the inputs, feel free,\n",
    "        but this is completely optional.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, X_pred_many):\n",
    "        \"\"\"\n",
    "        Predict classes of points given feature values in X_pred\n",
    "        \n",
    "        :param X_pred: a 2D numpy array of (transformed) feature values. Shape is (n x 2)\n",
    "        :return: a 1D numpy array of predicted classes (Automatically Rejected=0, Require Guarantor=1, Automatically Accepted=2).\n",
    "                 Shape should be (n,)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1739570692231,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "lonR3wrAvUQ0"
   },
   "outputs": [],
   "source": [
    "def phi(X):\n",
    "    \"\"\"\n",
    "    Transform [x_1, x_2] into basis [ln(x_1 + 10), x_2^2]\n",
    "\n",
    "    :param t: a 2D numpy array of values to transform. Shape is (n x 2)\n",
    "    :return: a 2D array in which each row corresponds to a basis transformation of\n",
    "             an input value. Shape should be (n x 2)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QqOVHgkvUQ0"
   },
   "source": [
    "## Plotting Function for Problem 3, Subpart 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1739570692878,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "8ZYCqyGTvUQ0"
   },
   "outputs": [],
   "source": [
    "# Visualize the decision boundary that a model produces\n",
    "def visualize_boundary(model, X, y, title, basis=None, width=10):\n",
    "    # Create a grid of points\n",
    "    x_min, x_max = min(X[:, 0]-width*0.15), max(X[:, 0]+width*0.15)\n",
    "    y_min, y_max = min(X[:, 1]-width*0.2), max(X[:, 1]+width*0.2)\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, 0.05),\n",
    "        np.arange(y_min, y_max, 0.05)\n",
    "    )\n",
    "\n",
    "    # Flatten the grid so the values match spec for self.predict\n",
    "    xx_flat = xx.flatten()\n",
    "    yy_flat = yy.flatten()\n",
    "    X_pred = np.vstack((xx_flat, yy_flat)).T\n",
    "\n",
    "    if basis is not None:\n",
    "        X_pred = basis(X_pred)\n",
    "\n",
    "    # Get the class predictions\n",
    "    Y_hat = model.predict(X_pred)\n",
    "    Y_hat = Y_hat.reshape((xx.shape[0], xx.shape[1]))\n",
    "\n",
    "    # Visualize them.\n",
    "    cmap = c.ListedColormap(['r', 'b', 'g'])\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Debt to Income Ratio')\n",
    "    plt.ylabel('Credit Score')\n",
    "\n",
    "    ticks = np.transpose(np.array([[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7],\n",
    "                                   [300, 400, 500, 600, 700, 800, 900, 1000]]))\n",
    "    transformed_ticks = transform(ticks)\n",
    "\n",
    "\n",
    "    plt.xticks(transformed_ticks[:,0],\n",
    "               ticks[:,0])\n",
    "    plt.yticks(transformed_ticks[:,1],\n",
    "               ticks[:,1])\n",
    "    plt.pcolormesh(xx, yy, Y_hat, cmap=cmap, alpha=0.3)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, linewidths=1,\n",
    "                edgecolors='black')\n",
    "\n",
    "    # Adding a legend and a title\n",
    "    red = mpatches.Patch(color='red', label='Automatically Rejected')\n",
    "    blue = mpatches.Patch(color='blue', label='Require Guarantor')\n",
    "    green = mpatches.Patch(color='green', label='Automatically Accepted')\n",
    "    plt.legend(handles=[red, blue, green])\n",
    "\n",
    "    # Saving the image to a file, and showing it as well\n",
    "    plt.savefig('img_output/' + title + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUs3MZdAvUQ1"
   },
   "source": [
    "## Problem 3, Subpart 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 680,
     "status": "ok",
     "timestamp": 1739570694086,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "XtxMaH8PvUQ1",
    "outputId": "fc50e23e-8d3b-485b-e036-dff44b124818"
   },
   "outputs": [],
   "source": [
    "# Fit models and visualize their decision boundaries\n",
    "\n",
    "# YOUR CODE HERE\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 165,
     "status": "ok",
     "timestamp": 1739570757554,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "_DtOrO23vUQ1",
    "outputId": "09380131-5bfa-418f-ed2c-e27016ae6830"
   },
   "outputs": [],
   "source": [
    "# You may test your models' correctness using test_p3_softmax and test_p3_knn\n",
    "# See T2_P3_TestCases.py for how the test functions are written\n",
    "# YOUR CODE HERE\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA09mP_KvUQ1"
   },
   "source": [
    "## Problem 3, Subpart 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1739570790275,
     "user": {
      "displayName": "Will Hahn",
      "userId": "03137104021071489773"
     },
     "user_tz": 300
    },
    "id": "1ptpkXpgdDle",
    "outputId": "0a7bb9bd-feff-4b09-af66-8dde87716902"
   },
   "outputs": [],
   "source": [
    "# Predicting for new applicant\n",
    "point = transform(np.array([(0.32, 350)]))\n",
    "point\n",
    "\n",
    "# YOUR CODE HERE\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Synthetic 2D regression problem\n",
    "# -----------------------------\n",
    "\n",
    "def make_problem(n: int = 120, seed: int = 0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # correlated + differently-scaled features -> ravine in loss\n",
    "    x0 = rng.normal(size=n)\n",
    "    x1 = 0.12 * x0\n",
    "    X = np.stack([x0, x1], axis=1)\n",
    "    w_true = np.array([300.0, -200])\n",
    "    y = X @ w_true + 0.12 * rng.normal(size=n)\n",
    "\n",
    "    # standardize\n",
    "    X = (X - X.mean(axis=0)) / (X.std(axis=0) + 1e-12)\n",
    "    y = y - y.mean()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Losses + gradients\n",
    "# -----------------------------\n",
    "def loss_linear(X, y, w):\n",
    "    \"\"\"Linear regression loss: L(w) = (1/2n) * sum_i (x_i^T w - y_i)^2\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def grad_linear(X, y, w):\n",
    "    \"\"\"Gradient of the linear regression loss w.r.t. w.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def mse(X, y, w):\n",
    "    \"\"\"Mean squared error (no 1/2 factor). Used for plotting.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def loss_ridge(X, y, w, lam):\n",
    "    \"\"\"Ridge loss: linear loss + (lambda/2) * ||w||^2\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def grad_ridge(X, y, w, lam):\n",
    "    \"\"\"Gradient of ridge loss: grad_linear + lambda * w\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Optimizers (stateful)\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class MomState:\n",
    "    v: np.ndarray\n",
    "\n",
    "def sgd_step(w, g, lr, state=None):\n",
    "    \"\"\"SGD update: w_{t+1} = w_t - lr * g_t\"\"\"\n",
    "    # TODO: return the updated weights and None for state\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        (w_new, state)\n",
    "    In this case, state is not used, but we return None for consistency with the other optimizers.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def mom_step(w, g, lr, beta, state: MomState | None):\n",
    "    \"\"\"\n",
    "    Momentum update:\n",
    "        v_{t+1} = beta * v_t + g_t\n",
    "        w_{t+1} = w_t - lr * v_{t+1}\n",
    "\n",
    "    Args:\n",
    "        w:     current weights\n",
    "        g:     current gradient\n",
    "        lr:    learning rate\n",
    "        beta:  momentum coefficient (e.g. 0.9)\n",
    "        state: MomState carrying the velocity vector (None on first call)\n",
    "\n",
    "    Returns:\n",
    "        (w_new, state)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "@dataclass\n",
    "class AdamState:\n",
    "    m: np.ndarray\n",
    "    v: np.ndarray\n",
    "    t: int\n",
    "\n",
    "def adam_step(w, g, lr, beta1, beta2, eps, state: AdamState | None):\n",
    "    \"\"\"\n",
    "    Adam update:\n",
    "        m_t = beta1 * m_{t-1} + (1 - beta1) * g_t\n",
    "        v_t = beta2 * v_{t-1} + (1 - beta2) * g_t^2\n",
    "        m_hat = m_t / (1 - beta1^t)        # bias correction\n",
    "        v_hat = v_t / (1 - beta2^t)        # bias correction\n",
    "        w_{t+1} = w_t - lr * m_hat / (sqrt(v_hat) + eps)\n",
    "\n",
    "    Args:\n",
    "        w:     current weights\n",
    "        g:     current gradient\n",
    "        lr:    learning rate\n",
    "        beta1: decay rate for first moment  (e.g. 0.9)\n",
    "        beta2: decay rate for second moment (e.g. 0.999)\n",
    "        eps:   small constant for numerical stability\n",
    "        state: AdamState (None on first call)\n",
    "\n",
    "    Returns:\n",
    "        (w_new, state)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_panel(\n",
    "    ax,\n",
    "    title,\n",
    "    loss_fn: Callable[[np.ndarray], float],\n",
    "    path: np.ndarray,\n",
    "    both_opt: tuple = None\n",
    "):\n",
    "    # ----------------------------------\n",
    "    # Include optima in plotting window\n",
    "    # ----------------------------------\n",
    "    key_pts = path\n",
    "\n",
    "    if both_opt is not None:\n",
    "        opt_1, opt_2 = both_opt\n",
    "\n",
    "        extra_pts = []\n",
    "        if opt_1 is not None:\n",
    "            extra_pts.append(opt_1.reshape(1, -1))\n",
    "        if opt_2 is not None:\n",
    "            extra_pts.append(opt_2.reshape(1, -1))\n",
    "\n",
    "        if extra_pts:\n",
    "            key_pts = np.vstack([path] + extra_pts)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Build contour grid\n",
    "    # ----------------------------------\n",
    "    pad_frac = 0.3\n",
    "    w0_lo, w0_hi = 40, 300\n",
    "    w1_lo, w1_hi = -75, 175\n",
    "    #w0_lo, w0_hi = key_pts[:, 0].min(), key_pts[:, 0].max()\n",
    "    #w1_lo, w1_hi = key_pts[:, 1].min(), key_pts[:, 1].max()\n",
    "\n",
    "    w0_pad = pad_frac * max(w0_hi - w0_lo, 1.0)\n",
    "    w1_pad = pad_frac * max(w1_hi - w1_lo, 1.0)\n",
    "\n",
    "    w0s = np.linspace(w0_lo - w0_pad, w0_hi + w0_pad, 300)\n",
    "    w1s = np.linspace(w1_lo - w1_pad, w1_hi + w1_pad, 300)\n",
    "\n",
    "    W0, W1 = np.meshgrid(w0s, w1s)\n",
    "\n",
    "    Z = np.zeros_like(W0)\n",
    "    for i in range(Z.shape[0]):\n",
    "        pts = np.stack([W0[i], W1[i]], axis=1)\n",
    "        Z[i] = np.array([loss_fn(p) for p in pts])\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Plot contours\n",
    "    # ----------------------------------\n",
    "    ax.contourf(W0, W1, Z, levels=40, cmap=cm.turbo)\n",
    "    ax.contour(W0, W1, Z, levels=18, linewidths=0.7, cmap=cm.turbo)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Plot path\n",
    "    # ----------------------------------\n",
    "    ax.plot(path[:, 0], path[:, 1], c=\"white\", linewidth=0.8, alpha=0.5)\n",
    "\n",
    "    n_pts = len(path)\n",
    "    norm = Normalize(vmin=0, vmax=n_pts - 1)\n",
    "    cmap = cm.magma\n",
    "\n",
    "    ax.scatter(\n",
    "        path[:, 0],\n",
    "        path[:, 1],\n",
    "        c=np.arange(n_pts),\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "        s=35,\n",
    "        edgecolor=\"white\",\n",
    "        linewidths=0.4,\n",
    "        zorder=5,\n",
    "    )\n",
    "\n",
    "    # Start (square) and end (star)\n",
    "    colors = cmap(norm(np.arange(n_pts)))\n",
    "    ax.scatter(\n",
    "        [path[0, 0]],\n",
    "        [path[0, 1]],\n",
    "        marker=\"s\",\n",
    "        s=120,\n",
    "        c=[colors[0]],\n",
    "        edgecolor=\"white\",\n",
    "        linewidths=1.5,\n",
    "        zorder=6,\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        [path[-1, 0]],\n",
    "        [path[-1, 1]],\n",
    "        marker=\"*\",\n",
    "        s=220,\n",
    "        c=[colors[-1]],\n",
    "        edgecolor=\"white\",\n",
    "        linewidths=1.5,\n",
    "        zorder=6,\n",
    "    )\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Plot optima\n",
    "    # ----------------------------------\n",
    "    if both_opt is not None:\n",
    "        opt_1, opt_2 = both_opt\n",
    "\n",
    "        # Line of solutions: w1 = 276 - w0\n",
    "        opt_line_x = np.linspace(70, 300, 500)\n",
    "        opt_line_y = 276 - opt_line_x\n",
    "        ax.plot(opt_line_x, opt_line_y, 'r--', linewidth=2, label = 'opt_1')\n",
    "\n",
    "\n",
    "        if opt_2 is not None:\n",
    "            ax.scatter(\n",
    "                opt_2[0],\n",
    "                opt_2[1],\n",
    "                marker=\"x\",\n",
    "                s=160,\n",
    "                c=\"blue\",\n",
    "                linewidths=3,\n",
    "                label=\"opt_2\",\n",
    "                zorder=7,\n",
    "            )\n",
    "\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    # ----------------------------------\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"w0\")\n",
    "    ax.set_ylabel(\"w1\")\n",
    "\n",
    "    ax.set_xlim(40, 300)\n",
    "    ax.set_ylim(-75, 175)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Run + record path\n",
    "# -----------------------------\n",
    "def run(\n",
    "    grad_fn: Callable[[np.ndarray], np.ndarray],\n",
    "    w0: np.ndarray,\n",
    "    steps: int,\n",
    "    stepper: Callable,\n",
    "    stepper_kwargs: dict,\n",
    "):\n",
    "    w = w0.copy()\n",
    "    path = [w.copy()]\n",
    "    state = None\n",
    "    for _ in range(steps):\n",
    "        g = grad_fn(w)\n",
    "        w, state = stepper(w, g, **stepper_kwargs, state=state)\n",
    "        path.append(w.copy())\n",
    "    return np.array(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_problem(seed=0)\n",
    "w_start = np.array([125.0, -25.0])\n",
    "\n",
    "steps = 20\n",
    "lam = 1\n",
    "\n",
    "# OLS optimum (depends on w_true through the generated data)\n",
    "w_opt_lin = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "# Ridge closed-form optimum\n",
    "I = np.eye(X.shape[1])\n",
    "w_opt_rid = np.linalg.solve(X.T @ X / len(y) + lam * I, X.T @ y / len(y))\n",
    "\n",
    "# Objective-specific functions (closures over X,y)\n",
    "lin_loss = lambda w: loss_linear(X, y, w)\n",
    "lin_grad = lambda w: grad_linear(X, y, w)\n",
    "\n",
    "rid_loss = lambda w: loss_ridge(X, y, w, lam)\n",
    "rid_grad = lambda w: grad_ridge(X, y, w, lam)\n",
    "\n",
    "# Hyperparams tuned so the paths look distinct + stable\n",
    "sgd_lr_lin = 0.12\n",
    "mom_lr_lin = 0.04\n",
    "adam_lr_lin = 20\n",
    "\n",
    "sgd_lr_rid = 0.10\n",
    "mom_lr_rid = 0.03\n",
    "adam_lr_rid = 25\n",
    "\n",
    "beta = 0.9\n",
    "beta1, beta2, eps = 0.8, 0.8, 1e-8\n",
    "\n",
    "# --- Linear paths ---\n",
    "p_lin_sgd  = run(lin_grad, w_start, steps, sgd_step,  dict(lr=sgd_lr_lin))\n",
    "p_lin_mom  = run(lin_grad, w_start, steps, mom_step,  dict(lr=mom_lr_lin, beta=beta))\n",
    "p_lin_adam = run(lin_grad, w_start, steps, adam_step, dict(lr=adam_lr_lin, beta1=beta1, beta2=beta2, eps=eps))\n",
    "\n",
    "# --- Ridge paths ---\n",
    "p_rid_sgd  = run(rid_grad, w_start, steps, sgd_step,  dict(lr=sgd_lr_rid))\n",
    "p_rid_mom  = run(rid_grad, w_start, steps, mom_step,  dict(lr=mom_lr_rid, beta=beta))\n",
    "p_rid_adam = run(rid_grad, w_start, steps, adam_step, dict(lr=adam_lr_rid, beta1=beta1, beta2=beta2, eps=eps))\n",
    "\n",
    "# --- Contour plots ---\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "\n",
    "both_opt = (w_opt_lin, w_opt_rid)\n",
    "\n",
    "contour_panel(axes[0, 0], \"Linear + SGD\",          lin_loss, p_lin_sgd,  both_opt)\n",
    "contour_panel(axes[0, 1], \"Linear + Momentum\",     lin_loss, p_lin_mom,  both_opt)\n",
    "contour_panel(axes[0, 2], \"Linear + Adam\",         lin_loss, p_lin_adam, both_opt)\n",
    "\n",
    "contour_panel(axes[1, 0], \"Ridge + SGD\",           rid_loss, p_rid_sgd,  both_opt)\n",
    "contour_panel(axes[1, 1], \"Ridge + Momentum\",      rid_loss, p_rid_mom,  both_opt)\n",
    "contour_panel(axes[1, 2], \"Ridge + Adam\",          rid_loss, p_rid_adam, both_opt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs181",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
